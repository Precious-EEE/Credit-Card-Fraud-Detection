# -*- coding: utf-8 -*-
"""CreditCard_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LslYdhvvmfcsY28u31Vrh3yqWylM5eXV

# Importation of Libraries
"""

!pip install xgboost

from google.colab import drive
drive.mount('/content/drive')

!pip install catboost

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

"""# Information on the Dataset"""

df_train = pd.read_csv("/content/drive/MyDrive/PS_20174392719_1491204439457_log.csv")
df_train.head()

df_train.info()

df_train.describe()

"""# EDA

Data Analysis
"""

import plotly.express as px
# Calculate value counts for the 'type' column
type_counts = df_train['type'].value_counts()

# Create a bar plot using Plotly Express
fig = px.bar(x=type_counts.index, y=type_counts.values, labels={'x': 'Transaction Type', 'y': 'Count'}, title='Transaction Type Distribution')

# Show the plot
fig.show()

plt.figure(figsize=(30, 20))
sns.displot(df_train, x = "amount",bins=30, color='blue', edgecolor='black', alpha=1)
plt.title("Amount")
plt.show()

#Filter data for fraud and non-fraud transactions
fraud_data = df_train[df_train['isFraud'] == 1]  # Assuming 'Class' column represents fraud (1) or non-fraud (0)
non_fraud_data = df_train[df_train['isFraud'] == 0]

# Create two histograms to visualize the distribution of transaction amounts
plt.figure(figsize=(12, 6))

# Plot for fraud transactions
plt.subplot(1, 2, 1)
plt.hist(fraud_data['amount'], bins=50, color='red', alpha=0.6)
plt.title('Distribution of Amount for Fraud Transactions')
plt.xlabel('Transaction Amount')
plt.ylabel('Frequency')

# Plot for non-fraud transactions
plt.subplot(1, 2, 2)
plt.hist(non_fraud_data['amount'], bins=50, color='green', alpha=0.6)
plt.title('Distribution of Amount for Non-Fraud Transactions')
plt.xlabel('Transaction Amount')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

# Data Visualizations (you can customize these based on your features)
plt.figure(figsize=(10, 6))
sns.countplot(x='isFlaggedFraud', data=df_train)
plt.title("Transaction Category Distribution")
plt.xticks(rotation=45)
plt.show()

# Create a boxplot to visualize the relationship between Amount and Type.
plt.figure(figsize=(12, 6))
sns.boxplot(x='type', y='amount', data=df_train)
plt.title('Relationship between Amount and Transaction Type')
plt.xlabel('Transaction Type')
plt.ylabel('Amount')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.show()

"""Outliers"""

# Create a box plot for each column to visualize outliers.
plt.figure(figsize=(12, 6))
df_train.boxplot(rot=90)
plt.title('Box Plot of Columns to Identify Outliers')
plt.ylabel('Value')
plt.show()

"""Correlation Analysis"""

# Correlation Analysis with Heatmap
corr_matrix = df_train.corr()
plt.figure(figsize=(20, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

"""Data Encoding"""

df_train["type"] = df_train["type"].map({"CASH_OUT": 1,
    "PAYMENT": 2,
    "CASH_IN": 3,
    "TRANSFER": 4,
    "DEBIT": 5
})
df_train.head()

"""Missing Value"""

df_train.isnull().sum()

"""# Scaling of the  amount columns"""

from sklearn.preprocessing import RobustScaler
#This code scales the 'amount' column in a DataFrame 'df_train' using RobustScaler, replaces the original column with scaled values, and drops the original 'amount' column.
rbs = RobustScaler()

df_small = df_train[["amount"]]
df_small = pd.DataFrame(rbs.fit_transform(df_small))

df_small.columns = ['scaled_Amount']
df_train = pd.concat([df_train,df_small],axis =1)

df_train.drop(['amount'], axis=1, inplace=True)
df_train.head()

"""# Balancing the class"""

#This code separates the 'df_train' DataFrame into two subsets, 'non_fraud' and 'fraud,' where 'non_fraud' contains non-fraudulent transactions, then randomly shuffles and selects a portion of 'non_fraud' to create a balanced dataset, and finally combines both subsets into a new DataFrame 'new_df' with shuffled rows.
non_fraud = df_train[df_train['isFraud']==0]
fraud = df_train[df_train['isFraud']==1]

non_fraud = non_fraud.sample(frac=1)
non_fraud = non_fraud[:8213]

new_df = pd.concat([non_fraud,fraud])
new_df = new_df.sample(frac=1)

df_train['isFraud'].value_counts()

sns.countplot(x='isFraud', data=df_train)

new_df['isFraud'].value_counts()

sns.countplot(x='isFraud', data=new_df)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

import xgboost as xgb
from catboost import CatBoostClassifier

"""# Modelling

##Modelling with Unbalanced Class

###Splitting the dataset
"""

x = df_train[["type", "scaled_Amount", "oldbalanceOrg", "newbalanceOrig"]]

y = df_train[["isFraud"]]

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=103)

"""###Logistic Regression Modeling"""

lr = LogisticRegression()
lr.fit(X_train,y_train)

#predicting using the model
pred = lr.predict(X_test)

#evaluating the predicted and the test
print(classification_report(y_test,pred))
print('\n')
print('accuracy is -->',round(accuracy_score(y_test,pred)*100,2))

Conf = confusion_matrix(y_test,pred)
print(Conf)

#visualizing the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(Conf, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Get feature importance scores (coefficients)
feature_importance = lr.coef_[0]

# Create a DataFrame to associate feature names with importance scores
feature_names = x.columns
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})

# Sort the features by importance
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Logistic Regression Feature Importance')
plt.gca().invert_yaxis()  # Invert the y-axis to display the most important features at the top
plt.show()

"""###Random forest Modeling"""

rf_classifier = RandomForestClassifier()
rf_classifier.fit(X_train, y_train)

#predicting using the model
rf_pred = rf_classifier.predict(X_test)

#evaluating the predicted and the test
print("Random Forest Classifier:")
print(classification_report(y_test, rf_pred))

print("\nAccuracy:", round(accuracy_score(y_test, rf_pred) * 100, 2))

Conf1 = confusion_matrix(y_test, rf_pred)
print("\nConfusion Matrix:\n", Conf1 )

#visualizing the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(Conf1, annot=True, fmt="d", cmap='BuPu')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Get feature importance scores (coefficients)
feature_importance = rf_classifier.feature_importances_

# Create a DataFrame to associate feature names with importance scores
feature_names = x.columns
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})

# Sort the features by importance
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Random forest Feature Importance')
plt.gca().invert_yaxis()  # Invert the y-axis to display the most important features at the top
plt.show()

"""###Xgboost Modeling"""

# Create an XGBoost classifier
model = xgb.XGBClassifier(
    learning_rate=0.1,  # Adjust as needed
    n_estimators=100,   # Adjust as needed
    max_depth=3,        # Adjust as needed
    random_state=42
)

# Train the model on the training data
model.fit(X_train, y_train)

#Make predictions on the test data
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)

classification_rep = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")

print("Classification Report:")
print(classification_rep)

confusion = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(confusion)

#visualizing the confusion matrix
colors = ["lightblue", "salmon"]
# Create a custom color map
cmap = sns.color_palette(colors)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, fmt="d", cmap=cmap)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Plot feature importance
xgb.plot_importance(model, importance_type='weight')  # You can change 'weight' to 'gain' or 'cover' for different types of importance
plt.title("Feature Importance")
plt.show()

"""###Catboost Modeling"""

# Initialize the CatBoost classifier with optional hyperparameters
catboost_classifier = CatBoostClassifier(iterations=100,  # Number of boosting iterations
                                         depth=6,         # Depth of the trees
                                         learning_rate=0.1,  # Learning rate
                                         loss_function='Logloss')  # Categorical feature indices

# Train the CatBoost classifier on the training data
catboost_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred_1 = catboost_classifier.predict(X_test)

# Calculate accuracy and display classification report
accuracy = accuracy_score(y_test, y_pred_1)

print(f'Accuracy: {accuracy:.2f}')
print(classification_report(y_test, y_pred_1))

confusion1 = confusion_matrix(y_test, y_pred_1)

print("Confusion Matrix:")
print(confusion1)

#visualizing the confusion matrix
# Define custom colors for True Negative (TN), False Positive (FP), False Negative (FN), and True Positive (TP)
colors = ["lightcoral", "lightgreen"]
# Create a custom color map
cmap = sns.color_palette(colors)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion1, annot=True, fmt="d", cmap=cmap)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Plot feature importance
feature_importance = catboost_classifier.get_feature_importance(type="FeatureImportance")
feature_names = X_train.columns  # Assuming your features are in a DataFrame

plt.figure(figsize=(10, 6))
plt.barh(feature_names, feature_importance)
plt.xlabel('Feature Importance')
plt.ylabel('Feature Name')
plt.title('CatBoost Classifier - Feature Importance')
plt.gca().invert_yaxis()  # Invert the y-axis for better visualization
plt.show()

"""##Modelling Balance Class

###Splitting the dataset
"""

x = new_df[["type", "scaled_Amount", "oldbalanceOrg", "newbalanceOrig"]]

y = new_df[["isFraud"]]

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=103)

"""###Logistic Regression Modeling"""

lr = LogisticRegression()
lr.fit(X_train,y_train)

#predicting using the model
pred = lr.predict(X_test)

#evaluating the predicted and the test
print(classification_report(y_test,pred))
print('\n')

print('accuracy is -->',round(accuracy_score(y_test,pred)*100,2))

Conf_mat = confusion_matrix(y_test,pred)
print(Conf_mat)

#visualizing the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(Conf_mat, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Get feature importance scores (coefficients)
feature_importance = lr.coef_[0]

# Create a DataFrame to associate feature names with importance scores
feature_names = x.columns
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})

# Sort the features by importance
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Logistic Regression Feature Importance')
plt.gca().invert_yaxis()  # Invert the y-axis to display the most important features at the top
plt.show()

"""###Random forest Modeling"""

rf_classifier = RandomForestClassifier()
rf_classifier.fit(X_train, y_train)

#predicting using the model
rf_pred = rf_classifier.predict(X_test)

#evaluating the predicted and the test
print("Random Forest Classifier:")
print(classification_report(y_test, rf_pred))
conf3 = confusion_matrix(y_test, rf_pred)
print("\nConfusion Matrix:\n",conf3 )
print("\nAccuracy:", round(accuracy_score(y_test, rf_pred) * 100, 2))

#visualizing the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf3, annot=True, fmt="d", cmap='BuPu')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Get feature importance scores (coefficients)
feature_importance = rf_classifier.feature_importances_

# Create a DataFrame to associate feature names with importance scores
feature_names = x.columns
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})

# Sort the features by importance
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Logistic Regression Feature Importance')
plt.gca().invert_yaxis()  # Invert the y-axis to display the most important features at the top
plt.show()

"""Sector Vector Machine Modeling"""

# Create an SVC classifier
from sklearn.svm import SVC

svc_classifier = SVC()
svc_classifier.fit(X_train, y_train)

# Predict using the trained SVC classifier
svc_pred = svc_classifier.predict(X_test)

# Print evaluation metrics
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print("Support Vector Classifier:")
print(classification_report(y_test, svc_pred))
conf4 = confusion_matrix(y_test, svc_pred)
print("\nConfusion Matrix:\n", conf4)
print("\nAccuracy:", round(accuracy_score(y_test, svc_pred) * 100, 2))

#visualizing the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf4, annot=True, fmt="d", cmap="YlOrRd")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Get feature importance scores (coefficients)
svc_classifier.kernel = 'linear'
feature_importance = svc_classifier.coef_

# Create a DataFrame to associate feature names with importance scores
feature_names = x.columns
feature_importance = feature_importance.reshape(-1)
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})

# Sort the features by importance
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Plot feature importance for SVC classifier
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('SVC Feature Importance')
plt.gca().invert_yaxis()  # Invert the y-axis to display the most important features at the top
plt.show()

"""Xgboost Modeling"""

# Create an XGBoost classifier
model1 = xgb.XGBClassifier(
    learning_rate=0.1,  # Adjust as needed
    n_estimators=100,   # Adjust as needed
    max_depth=3,        # Adjust as needed
    random_state=42
)

# Train the model on the training data
model1.fit(X_train, y_train)

#Make predictions on the test data
y_pred = model1.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
confusion = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print("Confusion Matrix:")
print(confusion)
print("Classification Report:")
print(classification_rep)

#visualizing the confusion matrix
# Define custom colors for True Negative (TN), False Positive (FP), False Negative (FN), and True Positive (TP)
colors = ["lightblue", "salmon"]
# Create a custom color map
cmap = sns.color_palette(colors)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, fmt="d", cmap=cmap)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Plot feature importance
xgb.plot_importance(model, importance_type='weight')  # You can change 'weight' to 'gain' or 'cover' for different types of importance
plt.title("Feature Importance")
plt.show()

"""Catboost Modeling"""

# Initialize the CatBoost classifier with optional hyperparameters
catboost_class = CatBoostClassifier(iterations=100,  # Number of boosting iterations
                                         depth=6,         # Depth of the trees
                                         learning_rate=0.1,  # Learning rate
                                         loss_function='Logloss')  # Categorical feature indices
# Train the CatBoost classifier on the training data
catboost_class.fit(X_train, y_train)

# Make predictions on the test set
y_pred = catboost_class.predict(X_test)

# Calculate accuracy and display classification report
accuracy = accuracy_score(y_test, y_pred)
confusion1 = confusion_matrix(y_test, y_pred)

print("Confusion Matrix:")
print(confusion1)
print(f'Accuracy: {accuracy:.2f}')
print(classification_report(y_test, y_pred))

#visualizing the confusion matrix
# Define custom colors for True Negative (TN), False Positive (FP), False Negative (FN), and True Positive (TP)
colors = ["lightcoral", "lightgreen"]
# Create a custom color map
cmap = sns.color_palette(colors)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion1, annot=True, fmt="d", cmap=cmap)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Plot feature importance
feature_importance = catboost_classifier.get_feature_importance(type="FeatureImportance")
feature_names = X_train.columns  # Assuming your features are in a DataFrame

plt.figure(figsize=(10, 6))
plt.barh(feature_names, feature_importance)
plt.xlabel('Feature Importance')
plt.ylabel('Feature Name')
plt.title('CatBoost Classifier - Feature Importance')
plt.gca().invert_yaxis()  # Invert the y-axis for better visualization
plt.show()